{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "215be4ee-b4f4-428e-983c-725b9af5a53f",
   "metadata": {},
   "source": [
    "# Group Project 002\n",
    "\n",
    "- *Submission Instruction*\n",
    "    - Clearly states your team number, team name, team members' first and last names and their contribution percentages.\n",
    "    - Please include **adequate comments/pseudocodes** in your script. Also, comments should also **highlight the Python concepts you adopted**. \n",
    "    - Team leader is responsible for submitting the script for the team to Canvas. You can submit either a Anaconda Cloud shared link or py/ipynb file. \n",
    "    - Script must be submitted before leaving the classroom.\n",
    "\n",
    "- *Requirements*\n",
    "    -  Must **exclusively** utilize Python concepts and techniques that have been covered in the class.\n",
    "    -  The use of external Python modules is strictly prohibited unless explicitly provided.\n",
    "\n",
    "- *Grading Criteria (Possible Surprising Points: 100)*\n",
    "    - **Correctness (40%)**: The code should function as intended, producing accurate outputs.\n",
    "    - **Readability (30%)**: Code readability is essential for collaborative work in professional environments. This includes clear and consistent naming conventions for variables and functions, as well as adequate but not too lengthy commenting (pseudocodes) to explain complex logic.\n",
    "    - **Conciseness (30%)**: While readable, codes should also be concise, avoiding unnecessary complexity or redundancy. For instance, repetitive codes can be avoided by defining functions, using walrus operator, or conditional expression, list/dictionary comprehensions, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4cd12d7-8aa2-4940-971c-307735ce078c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team Name: Pymatic\n",
      "('Team Member1', 'Contribution'): ('Kevin', '27%')\n",
      "('Team Member2', 'Contribution'): ('Jim', '25%')\n",
      "('Team Member3', 'Contribution'): ('Carlington', '24%')\n",
      "('Team Member4', 'Contribution'): ('Erich', '24%')\n"
     ]
    }
   ],
   "source": [
    "# please enter your team information here\n",
    "team_info = {\n",
    "     \"Team Name\": \"Pymatic\",\n",
    "    (\"Team Member1\", \"Contribution\"): (\"Kevin\", \"27%\"),\n",
    "    (\"Team Member2\", \"Contribution\"): (\"Jim\", \"25%\"),  # remove if not applicable\n",
    "    (\"Team Member3\", \"Contribution\"): (\"Carlington\", \"24%\"),   # remove if not applicable\n",
    "    (\"Team Member4\", \"Contribution\"): (\"Erich\", \"24%\")   # remove if not applicable\n",
    "\n",
    "}\n",
    "\n",
    "for k, v in team_info.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d37ea43-1c28-4e3b-8faf-bce839bd8370",
   "metadata": {
    "tags": []
   },
   "source": [
    "- **Task Description**\n",
    "\n",
    "    - Develop a Python program to read and analyze a text file named 'Preventing Ransomware Attacks at Scale.txt'. The program will extract and analyze words based on specific criteria, such as identifying frequent terms related to cybersecurity concepts and vulnerabilities.\n",
    "    - The task is decomposed into the following subtasks:\n",
    "    \n",
    "        - 1. Use Python's file handling methods to ```open and read``` the contents of 'Preventing Ransomware Attacks at Scale.txt'.\n",
    "        - 2. Try your best to clean each line by, e.g., removing punctuations, and split it into individual words. Please handle case sensitivity, e.g., treat 'Word' and 'word' as the same word. The use of the ```string``` module is permitted. \n",
    "               \n",
    "        - 3. ```Iterate``` over the list of words.\n",
    "              - Extract and count the frequency of words that end with specific cybersecurity-related suffixes, such as:\n",
    "              \n",
    "                   -'tion' (e.g., \"implementation\", \"prevention\").\n",
    "                   \n",
    "                   -'ing' (e.g., \"attacking\", \"defending\").\n",
    "                   \n",
    "                   -'ity' (e.g., \"security\", \"complexity\").\n",
    "\n",
    "        - 4. Store and Sort Data\n",
    "               - Store the words ending with the specified suffix in separate dictionaries, with the word as the key and its frequency as the value.\n",
    "               - Convert each dictionary into a list of tuples, where each tuple contains a frequency count and the corresponding word.\n",
    "               - Sort the lists in descending order of frequency using the sort() method.\n",
    "        - 5. Get the Top 10 Words for each suffix.\n",
    "             \n",
    "        - 6. Present the top 10 words for each suffix, using f-strings for formatting the results neatly. \n",
    "             \n",
    "    \n",
    "    - Please include reasonable pseudocodes and clearly comment which concepts covered in the class you have used to develop your program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8896143",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words ending with 'ing':\n",
      "including: 3\n",
      "working: 2\n",
      "bearing: 1\n",
      "responding: 1\n",
      "signing: 1\n",
      "reporting: 1\n",
      "creating: 1\n",
      "coding: 1\n",
      "damaging: 1\n",
      "allowing: 1\n",
      "\n",
      "Top 10 words ending with 'ity':\n",
      "security: 6\n",
      "vulnerability: 6\n",
      "cybersecurity: 4\n",
      "community: 1\n",
      "majority: 1\n",
      "responsibility: 1\n",
      "priority: 1\n",
      "reality: 1\n",
      "entity: 1\n",
      "\n",
      "Top 10 words ending with 'tion':\n",
      "injection: 8\n",
      "action: 2\n",
      "authentication: 2\n",
      "prescription: 1\n",
      "foundation: 1\n",
      "information: 1\n",
      "inaction: 1\n",
      "recommendation: 1\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "punctuations = string.punctuation + '“”'\n",
    "\n",
    "# Dictionaries to store different word counts -JC\n",
    "tion_word_count = {}\n",
    "ing_word_count = {}\n",
    "ity_word_count = {}\n",
    "\n",
    "\n",
    "# Open txt document for processing -JC\n",
    "with open('Preventing Ransomware Attacks at Scale.txt', 'r', encoding='UTF-8') as text:\n",
    "    for line in text:\n",
    "         # Clean and split line into words -JC\n",
    "        clean_words = [\n",
    "            word.strip(punctuations).lower()\n",
    "            for word in line.split()\n",
    "        ]\n",
    "\n",
    "        # Process words for each suffix -KA\n",
    "        for word in clean_words:\n",
    "            # Words ending with 'ing' -KA\n",
    "            if word.endswith(\"ing\"):\n",
    "                ing_word_count[word] = ing_word_count.get(word, 0) + 1\n",
    "\n",
    "            # Words ending with 'ity' -KA\n",
    "            if word.endswith(\"ity\"):\n",
    "                ity_word_count[word] = ity_word_count.get(word, 0) + 1\n",
    "\n",
    "            # Words ending with 'tion' -KA\n",
    "            if word.endswith(\"tion\"):\n",
    "                tion_word_count[word] = tion_word_count.get(word, 0) + 1\n",
    "\n",
    "\n",
    "# Function to sort and retrieve top 10 words -EM\n",
    "def get_top_10_words(word_count_dict):\n",
    "    # Convert dictionary to a list of tuples and sort by frequency in descending order -EM\n",
    "    sorted_items = sorted(word_count_dict.items(), key=sort_by_frequency, reverse=True)\n",
    "    return sorted_items[:10]\n",
    "\n",
    "# Helper function for sorting -EM\n",
    "def sort_by_frequency(item):\n",
    "    return item[1]\n",
    "\n",
    "# Retrieve top 10 words for each suffix -CM\n",
    "ing_top_10_words = get_top_10_words(ing_word_count)\n",
    "ity_top_10_words = get_top_10_words(ity_word_count)\n",
    "tion_top_10_words = get_top_10_words(tion_word_count)\n",
    "\n",
    "# Display the results -CM\n",
    "print(\"Top 10 words ending with 'ing':\")\n",
    "for word, count in ing_top_10_words:\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "print(\"\\nTop 10 words ending with 'ity':\")\n",
    "for word, count in ity_top_10_words:\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "print(\"\\nTop 10 words ending with 'tion':\")\n",
    "for word, count in tion_top_10_words:\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c402f4ec-380b-425c-b4ba-2e3cc2b69755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c7cbab-a958-4bf0-a8d3-2f6ead3474e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
